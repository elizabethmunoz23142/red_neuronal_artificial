# -*- coding: utf-8 -*-
"""Redes Neuronales Artificales - Prestamo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UkRXq5GQV6hq56IbhQRsRhRg0yHCv2cS
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow_datasets as tfds
import math

from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, mean_squared_error

import time

!pip install tensorflowjs
print("ok")

data = pd.read_csv('sample_data/Loan_Eligibility_1200.csv')

data.columns = [
    'ID_Cliente',
    'Genero',
    'Casado',
    'Dependientes',
    'Educacion',
    'Autoempleado',
    'Ingreso_Solicitante',
    'Ingreso_CoSolicitante',
    'Monto_Prestamo',
    'Plazo_Prestamo',
    'Historial_Credito',
    'Area_Propiedad',
    'Estado_Prestamo'
]

#Transformación de Datos
data['Genero'] = data['Genero'].map({'Male': 1, 'Female': 0})
data['Casado'] = data['Casado'].map({'Yes': 1, 'No': 0})
data['Estado_Prestamo'] = data['Estado_Prestamo'].map({'Y': 1, 'N': 0})
data['Educacion'] = data['Educacion'].map({'Graduate': 1, 'Not Graduate': 0})
data['Autoempleado'] = data['Autoempleado'].map({'Yes': 1, 'No': 0})
data = data.drop(['ID_Cliente'], axis=1)
data = pd.get_dummies(data, columns=['Area_Propiedad'], drop_first=True)

data.head()

data.count()

x = data[[
    'Genero',
    'Casado',
    'Dependientes',
    'Educacion',
    'Autoempleado',
    'Ingreso_Solicitante',
    'Ingreso_CoSolicitante',
    'Monto_Prestamo',
    'Plazo_Prestamo',
    'Historial_Credito',
    'Area_Propiedad_Semiurban',
    'Area_Propiedad_Urban']]
y = data['Estado_Prestamo']

x_train, x_test, y_train, y_test =  train_test_split(x,y,test_size=0.3,random_state=0)

#Opción de configuración #1
#capaIn     = tf.keras.layers.Input(shape=(12,))
#capaSalida = tf.keras.layers.Dense(units=1, activation='sigmoid')
#modelo     = tf.keras.Sequential([capaIn, capaSalida])

#Opción de configuración #2
#capaIn      = tf.keras.layers.Input(shape=(12,))
#capaOculta1 = tf.keras.layers.Dense(units=8, activation='relu')
#capaSalida  = tf.keras.layers.Dense(units=1, activation='sigmoid')
#modelo      = tf.keras.Sequential([capaIn, capaOculta1, capaSalida])

#Opción de configuración #3
#capaIn= tf.keras.layers.Dense(units=1, input_shape=[12])
#capaOculta1= tf.keras.layers.Dense(units=8)
#capaSalida= tf.keras.layers.Dense(units=1)
#modelo = tf.keras.Sequential([capaIn, capaOculta1, capaSalida])

#Opcón de configuración #4
X_train = np.asarray(x_train, dtype=np.float32)
X_test  = np.asarray(x_test,  dtype=np.float32)
y_train = np.asarray(y_train, dtype=np.float32).reshape(-1,)
y_test  = np.asarray(y_test,  dtype=np.float32).reshape(-1,)

norm = tf.keras.layers.Normalization(axis=-1)
norm.adapt(X_train)

modelo = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(12,), dtype=tf.float32),
    norm,
    tf.keras.layers.Dense(8, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid'),
])

modelo.compile(
    optimizer=tf.keras.optimizers.Adam(1e-3),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

print("Training ...")
start_time = time.time()
historial = modelo.fit(X_train, y_train, epochs=500, verbose=False)
end_time = time.time()
print("Finalizado en ",(end_time - start_time))

plt.xlabel("Iteración")
plt.ylabel("Error")
plt.plot(historial.history["loss"])

print("Última época -> loss:", historial.history["loss"][-1])

modelo.export('modelo_tfjs')
print("Modelo salvado - Ver sistema de archivos a la izquierda")

!mkdir folder
!tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model modelo_tfjs folder
print("ok")